{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "5\n",
      "Original Array:\n",
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n",
      "Padded Array:\n",
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "[1 2 3]\n",
      "[1 2 3]\n",
      "[4 5 6]\n",
      "[4 5 6]\n",
      "[7 8 9]\n",
      "[7 8 9]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# Example 2D NumPy array\n",
    "arr = np.array([[1, 2, 3],\n",
    "                [4, 5, 6],\n",
    "                [7, 8, 9]])\n",
    "\n",
    "# Get the shape of the array\n",
    "original_shape = arr.shape\n",
    "\n",
    "# Pad out the array with the final column\n",
    "padded_arr = np.pad(arr, ((0, 2), (0, 0)), mode='constant')\n",
    "\n",
    "print(original_shape[0])\n",
    "print(padded_arr.shape[0])\n",
    "\n",
    "print(\"Original Array:\")\n",
    "print(arr)\n",
    "print(\"Padded Array:\")\n",
    "print(padded_arr)\n",
    "\n",
    "for i, action in enumerate(arr):\n",
    "    print(action)\n",
    "    print(padded_arr[i,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(padded_arr[:3,...])\n",
    "for i, j in zip([1,2,3], [4,5,6]):\n",
    "    print(i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "esp32 = \"http://192.168.1.182\"\n",
    "\n",
    "import requests\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import h5py\n",
    "import argparse\n",
    "import time\n",
    "from visualize_episodes import visualize_joints, visualize_timestamp, save_videos\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from constants import DT\n",
    "\n",
    "import IPython\n",
    "e = IPython.embed\n",
    "\n",
    "JOINT_NAMES = [\"waist\", \"shoulder\", \"elbow\", \"forearm_roll\", \"wrist_angle\", \"wrist_rotate\"]\n",
    "STATE_NAMES = JOINT_NAMES + [\"gripper\"]\n",
    "\n",
    "MIRROR_STATE_MULTIPLY = np.array([-1, 1, 1, -1, 1, -1, 1]).astype('float32')\n",
    "MIRROR_BASE_MULTIPLY = np.array([1, -1]).astype('float32')\n",
    "\n",
    "def load_hdf5(dataset_dir, dataset_name):\n",
    "    dataset_path = os.path.join(dataset_dir, dataset_name + '.hdf5')\n",
    "    if not os.path.isfile(dataset_path):\n",
    "        print(f'Dataset does not exist at \\n{dataset_path}\\n')\n",
    "        exit()\n",
    "\n",
    "    with h5py.File(dataset_path, 'r') as root:\n",
    "        is_sim = root.attrs['sim']\n",
    "        compressed = root.attrs.get('compress', False)\n",
    "        qpos = root['/observations/qpos'][()]\n",
    "        # qvel = root['/observations/qvel'][()]\n",
    "        action = root['/action'][()]\n",
    "        image_dict = dict()\n",
    "        for cam_name in root[f'/observations/images/'].keys():\n",
    "            image_dict[cam_name] = root[f'/observations/images/{cam_name}'][()]\n",
    "        if 'base_action' in root.keys():\n",
    "            print('base_action exists')\n",
    "            base_action = root['/base_action'][()]\n",
    "        else:\n",
    "            base_action = None\n",
    "        if compressed:\n",
    "            compress_len = root['/compress_len'][()]\n",
    "\n",
    "    if compressed:\n",
    "        for cam_id, cam_name in enumerate(image_dict.keys()):\n",
    "            # un-pad and uncompress\n",
    "            padded_compressed_image_list = image_dict[cam_name]\n",
    "            image_list = []\n",
    "            for padded_compressed_image in padded_compressed_image_list: # [:1000] to save memory\n",
    "                image = cv2.imdecode(padded_compressed_image, 1)\n",
    "                image_list.append(image)\n",
    "            image_dict[cam_name] = np.array(image_list)\n",
    "\n",
    "    return qpos, action, base_action, image_dict, is_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/home/jonny/projects/mobile_aloha_world/episodes/task1\"\n",
    "dataset_name = 'episode_1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_action exists\n"
     ]
    }
   ],
   "source": [
    "qpos,  action, base_action, image_dict, is_sim = load_hdf5(data_dir, dataset_name)\n",
    "\n",
    "        # process proprioception\n",
    "qpos = np.array(qpos).astype('int32') #np.concatenate([qpos[:, 7:] * MIRROR_STATE_MULTIPLY, qpos[:, :7] * MIRROR_STATE_MULTIPLY], axis=1)\n",
    "# qvel = np.concatenate([qvel[:, 7:] * MIRROR_STATE_MULTIPLY, qvel[:, :7] * MIRROR_STATE_MULTIPLY], axis=1)\n",
    "action = np.array(action).astype('int32')  #np.concatenate([action[:, 7:] * MIRROR_STATE_MULTIPLY, action[:, :7] * MIRROR_STATE_MULTIPLY], axis=1)\n",
    "if base_action is not None:\n",
    "    base_action = np.array(base_action).astype('int32') #* MIRROR_BASE_MULTIPLY\n",
    "    while (base_action.shape[0] < action.shape[0]):\n",
    "        #pad out array\n",
    "        base_action=np.pad(base_action, ((0, 1), (0, 0)), mode='constant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_action.T.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming 'array' is your 4x150 array\n",
    "# array = [[n1_1, n1_2, ..., n1_150],\n",
    "#          [n2_1, n2_2, ..., n2_150],\n",
    "#          [n3_1, n3_2, ..., n3_150],\n",
    "#          [n4_1, n4_2, ..., n4_150]]\n",
    "\n",
    "def process_array(array):\n",
    "    array = array.T\n",
    "    result = np.zeros((2, array.shape[1])).astype('int32')  # Initialize result array\n",
    "    \n",
    "    # Extracting n1, n2, n3, and n4\n",
    "    n1 = array[0]\n",
    "    n2 = array[1]\n",
    "    n3 = array[2]\n",
    "    n4 = array[3]\n",
    "    \n",
    "    # Conditions\n",
    "    result[0] = np.where(n3 == 0, n1, np.where((n3 == 1) & (n4 == 1), 0, -n1))\n",
    "    result[1] = np.where(n3 == 0, n2, np.where((n3 == 1) & (n4 == 1), 0, -n2))\n",
    "    \n",
    "    return result.T\n",
    "new_array =process_array(base_action)\n",
    "# Example usage:\n",
    "# array = np.random.randint(10, size=(4, 150))  # Example random array\n",
    "# result_array = process_array(array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0959, -0.1301])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "all_action_data = []\n",
    "all_action_data.append(torch.from_numpy(new_array.astype('float')))\n",
    "all_action_data.append(torch.from_numpy(new_array.astype('float')))\n",
    "all_action_data = torch.cat(all_action_data, dim=0)\n",
    "all_action_data.mean(dim=[0]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change from rgb to bgr\n",
    "image_dict['top'] = image_dict['top'][:, :, ::-1]\n",
    "image_dict['base'] = image_dict['base'][:, :, ::-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {\n",
    "    '/observations/qpos': qpos,\n",
    "    # '/observations/qvel': qvel,\n",
    "    '/action': action,\n",
    "    '/base_action': base_action,\n",
    "} if base_action is not None else {\n",
    "    '/observations/qpos': qpos,\n",
    "    # '/observations/qvel': qvel,\n",
    "    '/action': action,\n",
    "}\n",
    "for cam_name in image_dict.keys():\n",
    "    if 'base' in image_dict.keys():\n",
    "        data_dict[f'/observations/images/{cam_name}'] = image_dict[cam_name]\n",
    "max_timesteps = len(qpos)\n",
    "\n",
    "COMPRESS = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146\n",
      "146\n",
      "compression: 0.75s\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), 50] # tried as low as 20, seems fine\n",
    "compressed_len = []\n",
    "for cam_name in image_dict.keys():\n",
    "    image_list = data_dict[f'/observations/images/{cam_name}']\n",
    "    print(len(image_list))\n",
    "    compressed_list = []\n",
    "    compressed_len.append([])\n",
    "    for image in image_list:\n",
    "        result, encoded_image = cv2.imencode('.jpg', image, encode_param) # 0.02 sec # cv2.imdecode(encoded_image, 1)\n",
    "        compressed_list.append(encoded_image)\n",
    "        compressed_len[-1].append(len(encoded_image))\n",
    "    data_dict[f'/observations/images/{cam_name}'] = compressed_list\n",
    "print(f'compression: {time.time() - t0:.2f}s')\n",
    "\n",
    "# pad so it has same length\n",
    "t0 = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3559, 3575, 3587, 3562, 3560, 3449, 3563, 3730, 3580, 3716, 3843, 3663, 3734, 3881, 3870, 3863, 3889, 3821, 3852, 3870, 3880, 3866, 3907, 3927, 3895, 3955, 3900, 3853, 3867, 3912, 3841, 3842, 3893, 4069, 4065, 4327, 4382, 4373, 4404, 4551, 4553, 4564, 4538, 4417, 4329, 4338, 4330, 4320, 4300, 4237, 4251, 5159, 5216, 5258, 5275, 5235, 5321, 5760, 5791, 5632, 5694, 5146, 4678, 4341, 3747, 3233, 3248, 3188, 3247, 3280, 3270, 3172, 3245, 3170, 3268, 3165, 3276, 3279, 3216, 3271, 3279, 3284, 3223, 4645, 5854, 5972, 5817, 5792, 5768, 5074, 4864, 4478, 4841, 4727, 4998, 4989, 5009, 4846, 4587, 4833, 4984, 4832, 5053, 5100, 5080, 5165, 5188, 5160, 4913, 4914, 5032, 5037, 5005, 5146, 5182, 4874, 4692, 4536, 4166, 4126, 4151, 4034, 4132, 4030, 4037, 4004, 4103, 4125, 4142, 4109, 4109, 3845, 3791, 3858, 3894, 3701, 3798, 3802, 3840, 3817, 3844, 3823, 3816, 3783, 3796, 3821], [29907, 29890, 29907, 29859, 29913, 30291, 29145, 29834, 29216, 28855, 28983, 28852, 28813, 29018, 28442, 28786, 28755, 28677, 28642, 28620, 28578, 28558, 28538, 28589, 28521, 28546, 28544, 28494, 28386, 28606, 28517, 28517, 28466, 28592, 28614, 28550, 28555, 28603, 28592, 28546, 28599, 28582, 28566, 28418, 28855, 28731, 28832, 28897, 28848, 28776, 28854, 28845, 28793, 28825, 28832, 28720, 28702, 28722, 28794, 28769, 28799, 28722, 28692, 28576, 28691, 28593, 28684, 28644, 28636, 28684, 28673, 28749, 28757, 28649, 28870, 28909, 28801, 28956, 28891, 28885, 28868, 28920, 28813, 28931, 28944, 28923, 28961, 28972, 28964, 28947, 28866, 28891, 28857, 28914, 28751, 28926, 28827, 28872, 28865, 28844, 28907, 28895, 28938, 28892, 28926, 28901, 28889, 28894, 28887, 28877, 28861, 28825, 28834, 28810, 28916, 28895, 28939, 28902, 28910, 28791, 28791, 28770, 28858, 28776, 28938, 28940, 28904, 29035, 29037, 29050, 29014, 29003, 28239, 28451, 28689, 29668, 30152, 30679, 30277, 30045, 30669, 29928, 30333, 30334, 30353, 30403]]\n"
     ]
    }
   ],
   "source": [
    "print(compressed_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3559  3575  3587  3562  3560  3449  3563  3730  3580  3716  3843  3663\n",
      "   3734  3881  3870  3863  3889  3821  3852  3870  3880  3866  3907  3927\n",
      "   3895  3955  3900  3853  3867  3912  3841  3842  3893  4069  4065  4327\n",
      "   4382  4373  4404  4551  4553  4564  4538  4417  4329  4338  4330  4320\n",
      "   4300  4237  4251  5159  5216  5258  5275  5235  5321  5760  5791  5632\n",
      "   5694  5146  4678  4341  3747  3233  3248  3188  3247  3280  3270  3172\n",
      "   3245  3170  3268  3165  3276  3279  3216  3271  3279  3284  3223  4645\n",
      "   5854  5972  5817  5792  5768  5074  4864  4478  4841  4727  4998  4989\n",
      "   5009  4846  4587  4833  4984  4832  5053  5100  5080  5165  5188  5160\n",
      "   4913  4914  5032  5037  5005  5146  5182  4874  4692  4536  4166  4126\n",
      "   4151  4034  4132  4030  4037  4004  4103  4125  4142  4109  4109  3845\n",
      "   3791  3858  3894  3701  3798  3802  3840  3817  3844  3823  3816  3783\n",
      "   3796  3821]\n",
      " [29907 29890 29907 29859 29913 30291 29145 29834 29216 28855 28983 28852\n",
      "  28813 29018 28442 28786 28755 28677 28642 28620 28578 28558 28538 28589\n",
      "  28521 28546 28544 28494 28386 28606 28517 28517 28466 28592 28614 28550\n",
      "  28555 28603 28592 28546 28599 28582 28566 28418 28855 28731 28832 28897\n",
      "  28848 28776 28854 28845 28793 28825 28832 28720 28702 28722 28794 28769\n",
      "  28799 28722 28692 28576 28691 28593 28684 28644 28636 28684 28673 28749\n",
      "  28757 28649 28870 28909 28801 28956 28891 28885 28868 28920 28813 28931\n",
      "  28944 28923 28961 28972 28964 28947 28866 28891 28857 28914 28751 28926\n",
      "  28827 28872 28865 28844 28907 28895 28938 28892 28926 28901 28889 28894\n",
      "  28887 28877 28861 28825 28834 28810 28916 28895 28939 28902 28910 28791\n",
      "  28791 28770 28858 28776 28938 28940 28904 29035 29037 29050 29014 29003\n",
      "  28239 28451 28689 29668 30152 30679 30277 30045 30669 29928 30333 30334\n",
      "  30353 30403]]\n",
      "30679\n"
     ]
    }
   ],
   "source": [
    "compressed_len = np.array(compressed_len)\n",
    "print(compressed_len)\n",
    "padded_size = compressed_len.max()\n",
    "print(padded_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30403"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoded_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[]]\n",
      "[[3]]\n"
     ]
    }
   ],
   "source": [
    "tmp=[]\n",
    "tmp.append([])\n",
    "print(tmp)\n",
    "tmp[-1].append(3)\n",
    "print(tmp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
